{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31286,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tqdm import tqdm\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-23T18:53:07.770484Z","iopub.execute_input":"2026-02-23T18:53:07.770750Z","iopub.status.idle":"2026-02-23T18:53:07.774640Z","shell.execute_reply.started":"2026-02-23T18:53:07.770728Z","shell.execute_reply":"2026-02-23T18:53:07.773919Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"##### Data #####\ndata = \"\"\"To be, or not to be, that is the question: Whether \\\n'tis nobler in the mind to suffer The slings and arrows of ou\\\ntrageous fortune, Or to take arms against a sea of troubles A\\\nnd by opposing end them. To die—to sleep, No more; and by a s\\\nleep to say we end The heart-ache and the thousand natural sh\\\nocks That flesh is heir to: 'tis a consummation Devoutly to b\\\ne wish'd. To die, to sleep; To sleep, perchance to dream—ay, \\\nthere's the rub: For in that sleep of death what dreams may c\\\nome, When we have shuffled off this mortal coil, Must give us\\\n pause—there's the respect That makes calamity of so long lif\\\ne. For who would bear the whips and scorns of time, Th'oppres\\\nsor's wrong, the proud man's contumely, The pangs of dispriz'\\\nd love, the law's delay, The insolence of office, and the spu\\\nrns That patient merit of th'unworthy takes, When he himself \\\nmight his quietus make\"\"\".lower()\n\nchars = set(data)\n\ndata_size, char_size = len(data), len(chars)\n\nprint(f'Data size: {data_size}, Char Size: {char_size}')\n\nchar_to_idx = {c:i for i, c in enumerate(chars)}\nidx_to_char = {i:c for i, c in enumerate(chars)}\n\ntrain_X, train_y = data[:-1], data[1:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-23T18:53:17.654465Z","iopub.execute_input":"2026-02-23T18:53:17.654733Z","iopub.status.idle":"2026-02-23T18:53:17.661166Z","shell.execute_reply.started":"2026-02-23T18:53:17.654710Z","shell.execute_reply":"2026-02-23T18:53:17.660502Z"}},"outputs":[{"name":"stdout","text":"Data size: 866, Char Size: 32\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"##### Helper Functions #####\ndef oneHotEncode(text):\n    output = np.zeros((char_size, 1))\n    output[char_to_idx[text]] = 1\n\n    return output\n\n# Xavier Normalized Initialization\ndef initWeights(input_size, output_size):\n    return np.random.uniform(-1, 1, (output_size, input_size)) * np.sqrt(6 / (input_size + output_size))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-23T18:53:30.854381Z","iopub.execute_input":"2026-02-23T18:53:30.854625Z","iopub.status.idle":"2026-02-23T18:53:30.859153Z","shell.execute_reply.started":"2026-02-23T18:53:30.854606Z","shell.execute_reply":"2026-02-23T18:53:30.858374Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"##### Activation Functions #####\ndef sigmoid(input, derivative = False):\n    if derivative:\n        return input * (1 - input)\n    \n    return 1 / (1 + np.exp(-input))\n\ndef tanh(input, derivative = False):\n    if derivative:\n        return 1 - input ** 2\n    \n    return np.tanh(input)\n\ndef softmax(input):\n    return np.exp(input) / np.sum(np.exp(input))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-23T18:53:45.134513Z","iopub.execute_input":"2026-02-23T18:53:45.134757Z","iopub.status.idle":"2026-02-23T18:53:45.140892Z","shell.execute_reply.started":"2026-02-23T18:53:45.134740Z","shell.execute_reply":"2026-02-23T18:53:45.139847Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"##### Long Short-Term Memory Network Class #####\nclass LSTM:\n    def __init__(self, input_size, hidden_size, output_size, num_epochs, learning_rate):\n        # Hyperparameters\n        self.learning_rate = learning_rate\n        self.hidden_size = hidden_size\n        self.num_epochs = num_epochs\n\n        # Forget Gate\n        self.wf = initWeights(input_size, hidden_size)\n        self.bf = np.zeros((hidden_size, 1))\n\n        # Input Gate\n        self.wi = initWeights(input_size, hidden_size)\n        self.bi = np.zeros((hidden_size, 1))\n\n        # Candidate Gate\n        self.wc = initWeights(input_size, hidden_size)\n        self.bc = np.zeros((hidden_size, 1))\n\n        # Output Gate\n        self.wo = initWeights(input_size, hidden_size)\n        self.bo = np.zeros((hidden_size, 1))\n\n        # Final Gate\n        self.wy = initWeights(hidden_size, output_size)\n        self.by = np.zeros((output_size, 1))\n        \n    # Reset Network Memory\n    def reset(self):\n        self.concat_inputs = {}\n\n        self.hidden_states = {-1:np.zeros((self.hidden_size, 1))}\n        self.cell_states = {-1:np.zeros((self.hidden_size, 1))}\n\n        self.activation_outputs = {}\n        self.candidate_gates = {}\n        self.output_gates = {}\n        self.forget_gates = {}\n        self.input_gates = {}\n        self.outputs = {}\n        \n    # Forward Propogation\n    def forward(self, inputs):\n        self.reset()\n\n        outputs = []\n        for q in range(len(inputs)):\n            self.concat_inputs[q] = np.concatenate((self.hidden_states[q - 1], inputs[q]))\n\n            self.forget_gates[q] = sigmoid(np.dot(self.wf, self.concat_inputs[q]) + self.bf)\n            self.input_gates[q] = sigmoid(np.dot(self.wi, self.concat_inputs[q]) + self.bi)\n            self.candidate_gates[q] = tanh(np.dot(self.wc, self.concat_inputs[q]) + self.bc)\n            self.output_gates[q] = sigmoid(np.dot(self.wo, self.concat_inputs[q]) + self.bo)\n\n            self.cell_states[q] = self.forget_gates[q] * self.cell_states[q - 1] + self.input_gates[q] * self.candidate_gates[q]\n            self.hidden_states[q] = self.output_gates[q] * tanh(self.cell_states[q])\n\n            outputs += [np.dot(self.wy, self.hidden_states[q]) + self.by]\n\n        return outputs\n        # Backward Propogation\n    def backward(self, errors, inputs):\n        d_wf, d_bf = 0, 0\n        d_wi, d_bi = 0, 0\n        d_wc, d_bc = 0, 0\n        d_wo, d_bo = 0, 0\n        d_wy, d_by = 0, 0\n\n        dh_next, dc_next = np.zeros_like(self.hidden_states[0]), np.zeros_like(self.cell_states[0])\n        for q in reversed(range(len(inputs))):\n            error = errors[q]\n\n            # Final Gate Weights and Biases Errors\n            d_wy += np.dot(error, self.hidden_states[q].T)\n            d_by += error\n\n            # Hidden State Error\n            d_hs = np.dot(self.wy.T, error) + dh_next\n\n            # Output Gate Weights and Biases Errors\n            d_o = tanh(self.cell_states[q]) * d_hs * sigmoid(self.output_gates[q], derivative = True)\n            d_wo += np.dot(d_o, inputs[q].T)\n            d_bo += d_o\n\n            # Cell State Error\n            d_cs = tanh(tanh(self.cell_states[q]), derivative = True) * self.output_gates[q] * d_hs + dc_next\n\n            # Forget Gate Weights and Biases Errors\n            d_f = d_cs * self.cell_states[q - 1] * sigmoid(self.forget_gates[q], derivative = True)\n            d_wf += np.dot(d_f, inputs[q].T)\n            d_bf += d_f\n\n            # Input Gate Weights and Biases Errors\n            d_i = d_cs * self.candidate_gates[q] * sigmoid(self.input_gates[q], derivative = True)\n            d_wi += np.dot(d_i, inputs[q].T)\n            d_bi += d_i\n            \n            # Candidate Gate Weights and Biases Errors\n            d_c = d_cs * self.input_gates[q] * tanh(self.candidate_gates[q], derivative = True)\n            d_wc += np.dot(d_c, inputs[q].T)\n            d_bc += d_c\n\n            # Concatenated Input Error (Sum of Error at Each Gate!)\n            d_z = np.dot(self.wf.T, d_f) + np.dot(self.wi.T, d_i) + np.dot(self.wc.T, d_c) + np.dot(self.wo.T, d_o)\n\n            # Error of Hidden State and Cell State at Next Time Step\n            dh_next = d_z[:self.hidden_size, :]\n            dc_next = self.forget_gates[q] * d_cs\n\n        for d_ in (d_wf, d_bf, d_wi, d_bi, d_wc, d_bc, d_wo, d_bo, d_wy, d_by):\n            np.clip(d_, -1, 1, out = d_)\n\n        self.wf += d_wf * self.learning_rate\n        self.bf += d_bf * self.learning_rate\n\n        self.wi += d_wi * self.learning_rate\n        self.bi += d_bi * self.learning_rate\n\n        self.wc += d_wc * self.learning_rate\n        self.bc += d_bc * self.learning_rate\n\n        self.wo += d_wo * self.learning_rate\n        self.bo += d_bo * self.learning_rate\n\n        self.wy += d_wy * self.learning_rate\n        self.by += d_by * self.learning_rate\n            # Train\n    def train(self, inputs, labels):\n        inputs = [oneHotEncode(input) for input in inputs]\n\n        for _ in tqdm(range(self.num_epochs)):\n            predictions = self.forward(inputs)\n\n            errors = []\n            for q in range(len(predictions)):\n                errors += [-softmax(predictions[q])]\n                errors[-1][char_to_idx[labels[q]]] += 1\n\n            self.backward(errors, self.concat_inputs)\n    \n    # Test\n    def test(self, inputs, labels):\n        accuracy = 0\n        probabilities = self.forward([oneHotEncode(input) for input in inputs])\n\n        output = ''\n        for q in range(len(labels)):\n            prediction = idx_to_char[np.random.choice([*range(char_size)], p = softmax(probabilities[q].reshape(-1)))]\n\n            output += prediction\n\n            if prediction == labels[q]:\n                accuracy += 1\n\n        print(f'Ground Truth:\\nt{labels}\\n')\n        print(f'Predictions:\\nt{\"\".join(output)}\\n')\n        \n        print(f'Accuracy: {round(accuracy * 100 / len(inputs), 2)}%')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-23T18:55:03.404753Z","iopub.execute_input":"2026-02-23T18:55:03.405049Z","iopub.status.idle":"2026-02-23T18:55:03.421294Z","shell.execute_reply.started":"2026-02-23T18:55:03.405030Z","shell.execute_reply":"2026-02-23T18:55:03.420347Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"\n# Initialize Network\nhidden_size = 25\n\nlstm = LSTM(input_size = char_size + hidden_size, hidden_size = hidden_size, output_size = char_size, num_epochs = 1_000, learning_rate = 0.05)\n\n##### Training #####\nlstm.train(train_X, train_y)\n\n##### Testing #####\nlstm.test(train_X, train_y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-23T18:55:08.742647Z","iopub.execute_input":"2026-02-23T18:55:08.743602Z","iopub.status.idle":"2026-02-23T18:56:23.230252Z","shell.execute_reply.started":"2026-02-23T18:55:08.743561Z","shell.execute_reply":"2026-02-23T18:56:23.229348Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 1000/1000 [01:14<00:00, 13.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Ground Truth:\nto be, or not to be, that is the question: whether 'tis nobler in the mind to suffer the slings and arrows of outrageous fortune, or to take arms against a sea of troubles and by opposing end them. to die—to sleep, no more; and by a sleep to say we end the heart-ache and the thousand natural shocks that flesh is heir to: 'tis a consummation devoutly to be wish'd. to die, to sleep; to sleep, perchance to dream—ay, there's the rub: for in that sleep of death what dreams may come, when we have shuffled off this mortal coil, must give us pause—there's the respect that makes calamity of so long life. for who would bear the whips and scorns of time, th'oppressor's wrong, the proud man's contumely, the pangs of dispriz'd love, the law's delay, the insolence of office, and the spurns that patient merit of th'unworthy takes, when he himself might his quietus make\n\nPredictions:\nto be, or not to be, that is the question: whether 'tis nobler in the mins oo suffer the slings and arrows of outrageous fortune, ir to take arms against a sea of troubler and my opposing end the i to dfs—to slenp, no mere; and by a sleep to say we end the heart-ache and the thousand natural shocks that flesh is heir to: 'tis a consummation devoutly to be wish'd. to die, to sleep; to sleep, perchance to dream—ay, there's the reb: for in that sleep of death w'at dreams may come, whek we hame thufflet off this mortal coil, must give us pause—there's the respect that makes calamity of so long life. for who would bear the whips and mcords offtome, thetpprestorts lrong, the proud man's contumely, the patgs of dispaiz'' love, the law's delay, the insolence of office, and the tpurns that patient merit sf th'unworthy takes, when he himself might his quietus make\n\nAccuracy: 96.42%\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}